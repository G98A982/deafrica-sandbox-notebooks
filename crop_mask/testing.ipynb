{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Notebook\n",
    "\n",
    "\n",
    "Random online python phenology functions that might help:\n",
    "\n",
    "- https://gist.github.com/YanCheng-go/d4e17831f294199443d0f7682558e608\n",
    "\n",
    "- https://github.com/JavierLopatin/PhenoPY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install richdem\n",
    "# !pip install xarray --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datacube\n",
    "import matplotlib.pyplot as plt\n",
    "from odc.algo import xr_reproject\n",
    "import hdstats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import xarray as xr\n",
    "import datetime as dt\n",
    "import os\n",
    "\n",
    "sys.path.append('../Scripts')\n",
    "from deafrica_datahandling import load_ard\n",
    "from deafrica_bandindices import calculate_indices\n",
    "from deafrica_plotting import display_map, rgb\n",
    "from deafrica_temporal_statistics import xr_phenology, temporal_statistics, fast_completion, smooth, allNaN_arg\n",
    "from datacube.utils.geometry import assign_crs\n",
    "from deafrica_dask import create_local_dask_cluster\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \"Mean of empty slice\")\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='Vegetation_phenology')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the vegetation proxy to use\n",
    "veg_proxy = 'NDVI'\n",
    "\n",
    "# Define area of interest\n",
    "lat = -34.288#22.817 #-34.288 \n",
    "lon = 20.012#28.518 #20.012 \n",
    "lon_buffer = 0.0175\n",
    "lat_buffer = 0.004\n",
    "\n",
    "# Combine central lat,lon with buffer to get area of interest\n",
    "lat_range = (lat-lat_buffer, lat+lat_buffer)\n",
    "lon_range = (lon-lon_buffer, lon+lon_buffer)\n",
    "\n",
    "# Set the range of dates for the analysis\n",
    "years_range = ('2018-01', '2018-12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the selected location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_map(x=lon_range, y=lat_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cloud-masked Sentinel-2 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to load Sentinel-2 data for the specified area of interest and time range. \n",
    "The `load_ard` function is used here to load data that has been masked for cloud, shadow and quality filters, making it ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reusable query\n",
    "query = {\n",
    "    'y': lat_range,\n",
    "    'x': lon_range,\n",
    "    'time': years_range,\n",
    "    'measurements': ['blue'],\n",
    "    'resolution': (-20,20),\n",
    "    'output_crs': 'epsg:6933'\n",
    "}\n",
    "\n",
    "# Load available data from Landsat 8\n",
    "# ds = load_ard(dc=dc,\n",
    "#               products=['s2_l2a'],\n",
    "#               dask_chunks={'x':1000, 'y':1000,'time':-1},\n",
    "#               **query\n",
    "#               )\n",
    "\n",
    "# Load available data from Landsat 8\n",
    "ds1 = load_ard(dc=dc,\n",
    "              products=['s2_l2a'],\n",
    "              **query\n",
    "              )\n",
    "\n",
    "# print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = ds1.blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_of_median(da, year, sample_lat, sample_lon):\n",
    "    \"\"\"\n",
    "    da = xr.DataArray\n",
    "        Assuming an annual time-series\n",
    "    year = str\n",
    "        year of time-series in 'da'\n",
    "    sample_lat = float\n",
    "        latitude pixel coordinate\n",
    "    sample_lon = float\n",
    "        longitude pixel coordinate\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #calculate medians for each month\n",
    "    monthly_medians = da.groupby('time.month').median()\n",
    "    \n",
    "    months = [str(i) for i in range(1,13)]\n",
    "    indexes = [i for i in range(0,12)]\n",
    "    \n",
    "    dates=[]\n",
    "    values=[]\n",
    "    for month, index in zip(months,indexes): \n",
    "        \n",
    "        #select the month of interest from da\n",
    "        m = da.sel(time=year+\"-\"+month)\n",
    "        \n",
    "        #find regions with all-NaN slices\n",
    "        mask = m.isnull().all('time')\n",
    "        \n",
    "        #calculate distance each pixel has from median\n",
    "        distance = m - monthly_medians.isel(month=index)\n",
    "        \n",
    "        #index of the absolute minimum distance\n",
    "        distance = distance.fillna(float(distance.max() + 1))\n",
    "        distance=xr.ufuncs.fabs(distance)\n",
    "        idx = distance.idxmin(dim='time', skipna=True).where(~mask)\n",
    "        value = distance.sel(time=idx, method='nearest')\n",
    "        values.append(value)\n",
    "        dates.append(idx)\n",
    "    \n",
    "    #join into dataarray along new dimension\n",
    "    dates = xr.concat(dates, \"date of median\")\n",
    "    dist_from_median = xr.concat(values, 'dist_from_monthly_median')\n",
    "    \n",
    "    #select pixel\n",
    "    dates = dates.sel(x=sample_lon, y=sample_lat, method='nearest')\n",
    "    dist_from_median = dist_from_median.sel(x=sample_lon, y=sample_lat, method='nearest')\n",
    "    \n",
    "    return dates, dist_from_median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=date_of_median(da, sample_lon=1929690., sample_lat=-4123870., year='2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.plot(col='median_month_argmin', col_wrap=4, vmax=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1929690"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.isel(day_of_month=1).time.dt.dayofyear.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_medians = da.groupby('time.month').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds1.blue.sel(time='2018-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = da.sel(time='2018-01') - monthly_medians.isel(month=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = distance.idxmax(dim='time', skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.sel(time=idx, method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = allNaN_arg(distance, \"time\", \"min\").astype(\"int16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_date = jan.isel(time=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_date.time.dt.dayofyear.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allNaN_arg(da, dim, stat):\n",
    "    \"\"\"\n",
    "    Calculate da.argmax() or da.argmin() while handling\n",
    "    all-NaN slices. Fills all-NaN locations with an\n",
    "    float and then masks the offending cells.\n",
    "    Params\n",
    "    ------\n",
    "    xarr : xarray.DataArray\n",
    "    dim : str, \n",
    "            Dimension over which to calculate argmax, argmin e.g. 'time'\n",
    "    stat : str,\n",
    "        The statistic to calculte, either 'min' for argmin()\n",
    "        or 'max' for .argmax()\n",
    "    Returns\n",
    "    ------\n",
    "    xarray.DataArray\n",
    "    \"\"\"\n",
    "    # generate a mask where entire axis along dimension is NaN\n",
    "    mask = da.isnull().all(dim)\n",
    "\n",
    "    if stat == \"max\":\n",
    "        y = da.fillna(float(da.min() - 1))\n",
    "        y = y.idxmax(dim=dim, skipna=True).where(~mask)\n",
    "        return y\n",
    "\n",
    "    if stat == \"min\":\n",
    "        y = da.fillna(float(da.max() + 1))\n",
    "        y = y.idxmax(dim=dim, skipna=True).where(~mask)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once the load is complete**, we can plot the data as a true-colour image using the `rgb` function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rgb(ds, index=[0,5], col_wrap=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the chosen vegetation proxy index and add it to the loaded data set\n",
    "# ds = (ds.nir - ds.red)/(ds.nir + ds.red)\n",
    "ds = calculate_indices(ds, index=veg_proxy, collection='s2')\n",
    "# ds1 = calculate_indices(ds1, index=veg_proxy, collection='s2')\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats=['discordance','abs_change','complexity','f_mean','central_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = temporal_statistics(ds1.NDVI, stats=stats)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "y = temporal_statistics(ds.NDVI, stats=stats).compute()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.discordance.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.discordance.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.discordance.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "phen = xr_phenology(ds.NDVI,\n",
    "                    method_sos='median',\n",
    "                    method_eos='median',\n",
    "                    complete='linear',\n",
    "                    smoothing='rolling_mean').compute()\n",
    "phen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "phen1 = xr_phenology(ds1.NDVI,\n",
    "                    method_sos='median',\n",
    "                    method_eos='median',\n",
    "                    complete='fast_complete',\n",
    "                    smoothing='wiener')\n",
    "phen1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z  = phen - phen1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phen.SOS.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phen1.SOS.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.SOS.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_complete=fast_completion(i.NDVI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_complete.mean(['x', 'y']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=smooth(i_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.mean(['x', 'y']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = I_mapblocks - i_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=i.NDVI.drop('spatial_ref')\n",
    "\n",
    "I_mapblocks = i.NDVI.map_blocks(\n",
    "    fast_completion,\n",
    "    template=template)\n",
    "\n",
    "# I_mapblocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=I_mapblocks\n",
    "\n",
    "I_mapblocks_smooth = I_mapblocks.map_blocks(\n",
    "    smooth,\n",
    "    template=template).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_mapblocks_smooth.mean(['x', 'y']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = I_mapblocks_smooth - x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j.mean(['x', 'y']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def poly_fit(time, data, degree):\n",
    "    \n",
    "#     pfit = np.polyfit(time, data, degree) \n",
    "    \n",
    "#     return np.transpose(np.polyval(pfit,time))\n",
    "\n",
    "# def poly_fit_smooth(time, data, degree, n_pts):\n",
    "#         \"\"\"\n",
    "#         \"\"\"\n",
    "    \n",
    "#         time_smooth_inds = np.linspace(0, len(time), n_pts)\n",
    "#         time_smooth = np.interp(time_smooth_inds, np.arange(len(time)), time)\n",
    "\n",
    "#         data_smooth = np.array([np.array([coef * (x_val ** current_degree) for\n",
    "#                                 coef, current_degree in zip(np.polyfit(time, data, degree),\n",
    "#                                 range(degree, -1, -1))]).sum() for x_val in time_smooth])\n",
    "\n",
    "#         return data_smooth\n",
    "\n",
    "# def xr_polyfit(doy,\n",
    "#                da,\n",
    "#                degree,\n",
    "#                interp_multiplier=1):    \n",
    "    \n",
    "#     # Fit polynomial curve to observed data points\n",
    "#     if interp_multiplier==1:\n",
    "#         print('Fitting polynomial curve to existing observations')\n",
    "#         pfit = xr.apply_ufunc(\n",
    "#             poly_fit,\n",
    "#             doy,\n",
    "#             da, \n",
    "#             kwargs={'degree':degree},\n",
    "#             input_core_dims=[[\"time\"], [\"time\"]], \n",
    "#             output_core_dims=[['time']],\n",
    "#             vectorize=True,  \n",
    "#             dask=\"parallelized\",\n",
    "#             output_dtypes=[da.dtype],\n",
    "#         )\n",
    "    \n",
    "#     if interp_multiplier > 1:\n",
    "#         print(\"Fitting polynomial curve to \"+str(len(doy)*interp_multiplier)+\n",
    "#                                                       \" interpolated points\")\n",
    "#         pfit = xr.apply_ufunc(\n",
    "#             poly_fit_smooth,  # The function\n",
    "#             doy,# time\n",
    "#             da,#.chunk({'time': -1}), #the data\n",
    "#             kwargs={'degree':degree, 'n_pts':len(doy)*interp_multiplier},\n",
    "#             input_core_dims=[[\"time\"], [\"time\"]], \n",
    "#             output_core_dims=[['new_time']], \n",
    "#             output_sizes = ({'new_time':len(doy)*interp_multiplier}),\n",
    "#             exclude_dims=set((\"time\",)),\n",
    "#             vectorize=True, \n",
    "#             dask=\"parallelized\",\n",
    "#             output_dtypes=[da.dtype],\n",
    "#         ).rename({'new_time':'time'})\n",
    "    \n",
    "#         # Map 'dayofyear' onto interpolated time dim\n",
    "#         time_smooth_inds = np.linspace(0, len(doy), len(doy)*interp_multiplier)\n",
    "#         new_datetimes = np.interp(time_smooth_inds, np.arange(len(doy)), doy)\n",
    "#         pfit = pfit.assign_coords({'time':new_datetimes})\n",
    "    \n",
    "#     return pfit\n",
    "\n",
    "# # da=xr_polyfit(dayofyear=dayofyear, \n",
    "# #               da=da,\n",
    "# #               degree=degree,\n",
    "# #               interp_multiplier=interp_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #set up figure\n",
    "# fig, ax = plt.subplots(nrows=5,ncols=2,figsize=(18,25), sharex=True, sharey=True)\n",
    "\n",
    "# #start of season\n",
    "# temp_stats.discordance.plot(ax=ax[0,0])\n",
    "# ax[0,0].set_title('discordance')\n",
    "# temp_stats.f_std.plot(ax=ax[0,1])\n",
    "# ax[0,1].set_title('f_std')\n",
    "\n",
    "# #peak of season\n",
    "# temp_stats.f_mean.plot(ax=ax[1,0])\n",
    "# ax[1,0].set_title('f_mean')\n",
    "# phen.f_median.plot(ax=ax[1,1])\n",
    "# ax[1,1].set_title('f_median')\n",
    "\n",
    "# #end of season\n",
    "# temp_stats.mean_change.plot(ax=ax[2,0])\n",
    "# ax[2,0].set_title('mean_change')\n",
    "# phen.med_change.plot(ax=ax[2,1])\n",
    "# ax[2,1].set_title('med_change')\n",
    "\n",
    "# #Length of Season\n",
    "# temp_stats.abs_change.plot(ax=ax[3,0])\n",
    "# ax[3,0].set_title('abs_change');\n",
    "\n",
    "# #Amplitude\n",
    "# temp_stats.complexity.plot(ax=ax[3,1])\n",
    "# ax[3,1].set_title('complexity')\n",
    "\n",
    "# #rate of growth\n",
    "# temp_stats.central_diff.plot(ax=ax[4,0])\n",
    "# ax[4,0].set_title('central_diff')\n",
    "\n",
    "# #rate of Sensescence\n",
    "# temp_stats.num_peaks.plot(ax=ax[4,1])\n",
    "# ax[4,1].set_title('num_peaks');\n",
    "\n",
    "# plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1d2ba241bfd2437dbdf5d4530c685d9a": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletAttributionControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "prefix"
       ],
       "position": "bottomright",
       "prefix": "Leaflet"
      }
     },
     "d867097fe154472198694ed8095e3b0c": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletZoomControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "zoom_in_text",
        "zoom_in_title",
        "zoom_out_text",
        "zoom_out_title"
       ]
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
