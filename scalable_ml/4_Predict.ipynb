{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction <img align=\"right\" src=\"../Supplementary_data/DE_Africa_Logo_Stacked_RGB_small.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "from odc.algo import xr_geomedian\n",
    "import xarray as xr\n",
    "import subprocess as sp\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "import geopandas as gpd\n",
    "from datacube.utils import geometry\n",
    "from datacube.utils.cog import write_cog\n",
    "from datacube.utils.geometry import assign_crs\n",
    "\n",
    "import sys\n",
    "sys.path.append('../Scripts')\n",
    "from deafrica_datahandling import load_ard\n",
    "from deafrica_classificationtools import predict_xr, predict_proba_xr\n",
    "from deafrica_dask import create_local_dask_cluster\n",
    "from deafrica_plotting import map_shapefile\n",
    "from deafrica_bandindices import calculate_indices\n",
    "from deafrica_temporal_statistics import temporal_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a dask cluster\n",
    "This will help keep our memory use down and conduct the analysis in parallel. If you'd like to view the dask dashboard, click on the hyperlink that prints below the cell. You can use the dashboard to monitor the progress of calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis parameters\n",
    "\n",
    "* `ncpus`: Set this value to > 1 to parallize the collection of training data. eg. npus=8. \n",
    "* `model`: Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically detect number of cpus, adjust to [-3:] if working on deafault Sandbox\n",
    "ncpus= int(float(sp.getoutput('env | grep CPU')[-4:]))\n",
    "\n",
    "model_path = 'results/ml_model.joblib'\n",
    "\n",
    "print('ncpus = '+str(ncpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open 'tiles' shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read shapefile\n",
    "gdf = gpd.read_file('../crop_mask/data/tiles.shp')\n",
    "\n",
    "#open shapefile\n",
    "aez=gpd.read_file('../crop_mask/data/AEZs/Southern.shp')\n",
    "\n",
    "# clip points to region\n",
    "gdf = gpd.overlay(gdf, aez, how='intersection')\n",
    "\n",
    "# add an ID column\n",
    "gdf['id']=range(0, len(gdf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print gdf\n",
    "list_of_tiles = [3,6,9,11,17,26]\n",
    "\n",
    "map_shapefile(gdf.iloc[list_of_tiles], 'id', hover_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction\n",
    "\n",
    "Extract data from the datacube exactly matching the feature layers we created during the extraction of training data in script `1_Extract_training_data.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporalStats_and_elevation(ds):   \n",
    "    \n",
    "    # summarise the surface reflectance bands\n",
    "    sr = ds.median('time').compute()\n",
    "    \n",
    "    # ndvi time series\n",
    "    ndvi = calculate_indices(ds,\n",
    "                             index=['NDVI'],\n",
    "                             drop=True,\n",
    "                             collection='s2')\n",
    "    \n",
    "    # calculate some temporal stats\n",
    "    print('temporal')\n",
    "    ts = temporal_statistics(ndvi.NDVI,\n",
    "                       stats=['f_mean','abs_change',\n",
    "                              'complexity','central_diff']).compute()\n",
    "    \n",
    "    # Load elevation data using the spatial coords from ds\n",
    "    elev = dc.load(product='srtm', like=ds.geobox).squeeze()\n",
    "    \n",
    "    #merge the results so we return a single xarray.Dataset\n",
    "    result = xr.merge([ts,sr,elev], compat='override')\n",
    "    \n",
    "    #reassign crs/geobox\n",
    "    result = assign_crs(result, crs=ds.geobox.crs)\n",
    "    \n",
    "    return result.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up our inputs to collect_training_data\n",
    "products =  ['s2_l2a']\n",
    "time = ('2019-01','2019-12')\n",
    "\n",
    "# Set up the inputs for the ODC query\n",
    "measurements =  ['red', 'nir', 'blue', 'swir_1', 'swir_2']\n",
    "resolution = (-30,30)\n",
    "output_crs='epsg:6933'\n",
    "dask_chunks={'x':1000,'y':1000,'time':-1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_classified = []\n",
    "\n",
    "for index, row in gdf.iloc[list_of_tiles].iterrows():\n",
    "\n",
    "    print(\"Working on tile: \"+str(gdf['id'][index]))\n",
    "    \n",
    "    # generate a datacube query object\n",
    "    query = {\n",
    "        'time': time,\n",
    "        'measurements': measurements,\n",
    "        'resolution': resolution,\n",
    "        'output_crs': output_crs,\n",
    "        'group_by' : 'solar_day',\n",
    "    }\n",
    "    \n",
    "    # Get the geometry\n",
    "    geom = geometry.Geometry(row.geometry.__geo_interface__,\n",
    "                             geometry.CRS(f'EPSG:{gdf.crs.to_epsg()}'))\n",
    "    \n",
    "    # Update dc query with geometry      \n",
    "    query.update({'geopolygon': geom})\n",
    "\n",
    "    ds = load_ard(dc=dc,\n",
    "                  products=products,\n",
    "                  dask_chunks=dask_chunks,\n",
    "                  **query)\n",
    "\n",
    "    data = temporalStats_and_elevation(ds)\n",
    "    \n",
    "    #predict using the imported model\n",
    "    print('predicting...')\n",
    "    predicted = predict_xr(model, data.squeeze(), progress=True)\n",
    "    tiles_classified.append(predicted)    \n",
    "    write_cog(predicted, 'results/classifications/Southern_'+ str(row['id'])+'_prediction.tif')\n",
    "    \n",
    "#     predicted_proba = predict_proba_xr(model, data.squeeze(), progress=True)\n",
    "#     write_cog(predicted_proba, 'results/classifications/Southern_'+ row['id']+'_prediction_proba.tif')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
