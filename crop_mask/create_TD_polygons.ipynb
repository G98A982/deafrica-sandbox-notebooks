{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating random training data polygons\n",
    "\n",
    "Using Collect Earth Online (CEO), these randomly scattered polygons will be classified as crop, non-crop, or mixed and form the knowledge base for the machine learning classifier.\n",
    "\n",
    "Using GEOGLAM's current crop-mask (ASAP) to stratify the points\n",
    "\n",
    "    gdalwarp -tr 0.0005389891704717132 0.0005389891704717132  -r mode GFSAD_mosaic.tif GFSAD_mosaic_60m.tif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from datacube.utils.cog import write_cog\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datacube\n",
    "\n",
    "import sys\n",
    "sys.path.append('../Scripts')\n",
    "from deafrica_spatialtools import xr_rasterize\n",
    "from deafrica_dask import create_local_dask_cluster\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asap_crop_mask = 'data/asap_mask_crop_v03.tif'\n",
    "crop_mask_shp = 'data/GFSAD/GFSAD_mosaic_60m.tif'\n",
    "\n",
    "#AEZ to mask crop mask\n",
    "aez = 'data/AEZs/Southern.shp'\n",
    "name = 'Southern'\n",
    "#location and file name to store shapefiles.\n",
    "out_fname = 'data/training_validation/collect_earth/Southern_TD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open AEZ shapefile\n",
    "aez = gpd.read_file(aez)\n",
    "\n",
    "#find bouding box\n",
    "xmin,ymin,xmax,ymax = aez.bounds.values[0][0], aez.bounds.values[0][1], aez.bounds.values[0][2], aez.bounds.values[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xr.open_rasterio(crop_mask_shp).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open GFSAD cropmask at bounding coords of AEZ\n",
    "crop_mask = xr.open_rasterio(crop_mask_shp).squeeze().sel(x=slice(xmin,xmax),\n",
    "                                                          y=slice(ymax,ymin)).chunk({'x':3000, 'y':3000})\n",
    "attrs = crop_mask.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask by AEZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aez_raster = xr_rasterize(aez, crop_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_mask = crop_mask.where(aez_raster).astype(np.int8)\n",
    "crop_mask.attrs = attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_mask = crop_mask.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_cog(crop_mask,\n",
    "#           'data/GFSAD/' + name + '_GFSAD.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datacube.helpers import write_geotiff\n",
    "write_geotiff('data/GFSAD/' + name + '_GFSAD.tif',\n",
    "                crop_mask.to_dataset(name='Southern_GFSAD'),\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reclassify\n",
    "\n",
    "Pixels in the ASAP cropmask refer to the percentage of crop in each pixel, scaled to 0-200.  Reclassifying so values >150 (i.e. 75% crop) are labelled as '2', values between 1-150 are labelled as '1', and 0 stays as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop_mask_aez = xr.where((crop_mask_aez >=1) & (crop_mask_aez <= 150), 1, crop_mask_aez)\n",
    "# crop_mask_aez = xr.where(crop_mask_aez > 150, 2, crop_mask_aez)\n",
    "\n",
    "# #add back attributes\n",
    "# crop_mask_aez.attrs = crop_mask.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop_mask_aez.plot(figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random points\n",
    "\n",
    "2000 random points: 50% (1000) in 2, 25% (500) in 1, 25% (500) in 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_points = random_sampling(crop_mask_aez,\n",
    "                     n=2000,\n",
    "                     sampling='manual',\n",
    "                     manual_class_ratios={'0.0':500, '1.0':500, '2.0':1000})\n",
    "\n",
    "#add a PLOTID field to satisfy CEO\n",
    "gdf_points['PLOTID'] = range(0,len(gdf_points))\n",
    "gdf_points['SAMPLEID'] = range(0,len(gdf_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_points = gdf_points.drop('band',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_points.plot(figsize=(8,6), column='PLOTID', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert points to square polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set radius (in metres) around points\n",
    "radius = 30\n",
    "\n",
    "#convert to equal area to set polygon size in metres\n",
    "gdf_poly = gdf_points.to_crs('EPSG:6933')\n",
    "\n",
    "#create circle buffer around points, then find envelope\n",
    "gdf_poly['geometry'] = gdf_poly['geometry'].buffer(radius).envelope\n",
    "\n",
    "#Convert back to lat/lon\n",
    "gdf_poly = gdf_poly.to_crs('EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to file\n",
    "gdf_poly.to_file(out_fname + '_polys.shp')\n",
    "\n",
    "gdf_points.to_file(out_fname + '_points.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(da,\n",
    "                    n,\n",
    "                    sampling='stratified_random',\n",
    "                    manual_class_ratios=None,\n",
    "                    out_fname=None\n",
    "                   ):\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates randomly sampled points for post-classification\n",
    "    accuracy assessment.\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    da: xarray.DataArray\n",
    "        A classified 2-dimensional xarray.DataArray\n",
    "    n: int\n",
    "        Total number of points to sample. Ignored if providing\n",
    "        a dictionary of {class:numofpoints} to 'manual_class_ratios'\n",
    "    sampling: str\n",
    "        'stratified_random' = Create points that are randomly \n",
    "        distributed within each class, where each class has a\n",
    "        number of points proportional to its relative area. \n",
    "        'equal_stratified_random' = Create points that are randomly\n",
    "        distributed within each class, where each class has the\n",
    "        same number of points.\n",
    "        'random' = Create points that are randomly distributed\n",
    "        throughout the image.\n",
    "        'manual' = user definined, each class is allocated a \n",
    "        specified number of points, supply a manual_class_ratio \n",
    "        dictionary mapping number of points to each class\n",
    "    manual_class_ratios: dict\n",
    "        If setting sampling to 'manual', the provide a dictionary\n",
    "        of type {'class': numofpoints} mapping the number of points\n",
    "        to generate for each class.\n",
    "    out_fname: str\n",
    "        If providing a filepath name, e.g 'sample_points.shp', the\n",
    "        function will export a shapefile/geojson of the sampling\n",
    "        points to file.\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    GeoPandas.Dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if sampling not in ['stratified_random', 'equal_stratified_random', 'random', 'manual']:\n",
    "        raise ValueError(\"Sampling strategy must be one of 'stratified_random', \"+\n",
    "                             \"'equal_stratified_random', 'random', or 'manual'\") \n",
    "    \n",
    "    #open the dataset as a pandas dataframe\n",
    "    da = da.squeeze()\n",
    "    df = da.to_dataframe(name='class')\n",
    "    \n",
    "    #list to store points\n",
    "    samples = []\n",
    "    \n",
    "    if sampling == 'stratified_random':\n",
    "        #determine class ratios in image\n",
    "        class_ratio = pd.DataFrame({'proportion': df['class'].value_counts(normalize=True),\n",
    "                            'class':df['class'].dropna().unique()\n",
    "                                 })\n",
    "        \n",
    "        for _class in class_ratio['class']:\n",
    "            #use relative proportions of classes to sample df\n",
    "            no_of_points = n * class_ratio[class_ratio['class']==_class]['proportion'].values[0]\n",
    "            #random sample each class\n",
    "            print('Class '+ str(_class)+ ': sampling at '+ str(round(no_of_points)) + ' coordinates')\n",
    "            sample_loc = df[df['class'] == _class].sample(n=int(round(no_of_points)))\n",
    "            samples.append(sample_loc)\n",
    "\n",
    "    if sampling == 'equal_stratified_random':\n",
    "        classes = df['class'].dropna().unique()\n",
    "        \n",
    "        for _class in classes:\n",
    "            #use relative proportions of classes to sample df\n",
    "            no_of_points = n / len(classes)\n",
    "            #random sample each classes\n",
    "            try:\n",
    "                sample_loc = df[df['class'] == _class].sample(n=int(round(no_of_points)))\n",
    "                print('Class '+ str(_class)+ ': sampling at '+ str(round(no_of_points)) + ' coordinates')\n",
    "                samples.append(sample_loc)\n",
    "            \n",
    "            except ValueError:\n",
    "                        print('Requested more sample points than population of pixels for class '+ str(_class)+', skipping')\n",
    "                        pass\n",
    "    \n",
    "    if sampling == 'random':\n",
    "        no_of_points = n\n",
    "        #random sample entire df\n",
    "        print('Randomly sampling dataAraay at '+ str(round(no_of_points)) + ' coordinates')\n",
    "        sample_loc = df.dropna().sample(n=int(round(no_of_points)))\n",
    "        samples.append(sample_loc)\n",
    "    \n",
    "    if sampling == 'manual':\n",
    "        if isinstance(manual_class_ratios, dict):\n",
    "            #check classes in dict match classes in data\n",
    "            classes = df['class'].dropna().unique()\n",
    "            dict_classes = list(manual_class_ratios.keys())\n",
    "            \n",
    "            if set(dict_classes).issubset([str(i) for i in classes]):\n",
    "                #mask for just those classes in the provided dictionary\n",
    "                mask = np.isin(classes,\n",
    "                               np.array(dict_classes).astype(type(classes[0])))\n",
    "                classes = classes[mask]               \n",
    "                #run sampling\n",
    "                for _class in classes:\n",
    "                    no_of_points = manual_class_ratios.get(str(_class))\n",
    "                    #random sample each class\n",
    "                    try:\n",
    "                        sample_loc = df[df['class'] == _class].sample(n=int(round(no_of_points)))\n",
    "                        print('Class '+ str(_class)+ ': sampled at '+ str(round(no_of_points)) + ' coordinates')\n",
    "                        samples.append(sample_loc)\n",
    "                        \n",
    "                    except ValueError:\n",
    "                        print('Requested more sample points than population of pixels for class '+ str(_class)+', skipping')\n",
    "                        pass\n",
    "\n",
    "            else:\n",
    "                raise ValueError(\"Some or all of the classes in 'manual_class_ratio' dictionary do not\" +\n",
    "                                 \" match the classes in the supplied dataArray. \"+\n",
    "                                \"DataArray classes: \"+str(classes)+\", Supplied dict classes: \"+\n",
    "                                 str(list(manual_class_ratios.keys())))\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Must supply a dictionary mapping {'class': numofpoints} if sampling\" +\n",
    "                             \" is set to 'manual'\")\n",
    "    \n",
    "    #join back into single datafame\n",
    "    all_samples = pd.concat([samples[i] for i in range(0,len(samples))])\n",
    "        \n",
    "    #get pd.mulitindex coords as list \n",
    "    y = [i[0] for i in list(all_samples.index)]\n",
    "    x = [i[1] for i in list(all_samples.index)]\n",
    "\n",
    "    #create geopandas dataframe\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        all_samples,\n",
    "        crs=da.crs,\n",
    "        geometry=gpd.points_from_xy(x,y)).reset_index()\n",
    "\n",
    "    gdf = gdf.drop(['x', 'y'],axis=1)\n",
    "    \n",
    "    if out_fname is not None:\n",
    "        gdf.to_file(out_fname)\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
