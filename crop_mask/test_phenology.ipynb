{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the creation of a 'xr_phenology' function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random online python phenology functions that might help:\n",
    "\n",
    "- https://gist.github.com/YanCheng-go/d4e17831f294199443d0f7682558e608\n",
    "\n",
    "- https://github.com/JavierLopatin/PhenoPY\n",
    "\n",
    "**UPDATE 25-5-2020**\n",
    " - `xr_phenology` is now working on 1D xarrays, but fails on 3D arrays because the `da.sel(time=slice(etc))` method cannot select a different time slice per-pixel...\n",
    " - `xr_polyfit_smooth` works on 3D arrays.\n",
    "     - Doesn't yet handle NaNs, and requires documenting. \n",
    "     - Time dimension is returned as a simple integer representing the DOY. \n",
    "     - Should consider mapping this back to proper dates...\n",
    "     - how would the function handle a timeseries that went across a calender year?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.6/site-packages/datacube/storage/masking.py:4: DeprecationWarning: datacube.storage.masking has moved to datacube.utils.masking\n",
      "  category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import datacube\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import deafrica_phenology\n",
    "sys.path.append('../Scripts')\n",
    "from deafrica_plotting import display_map, rgb\n",
    "from deafrica_datahandling import mostcommon_crs, load_ard\n",
    "from deafrica_bandindices import calculate_indices\n",
    "from deafrica_phenology import xr_phenology\n",
    "from deafrica_dask import create_local_dask_cluster\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_local_dask_cluster(aws_unsigned=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load some data to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='phenology stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat = -10.6976\n",
    "# lon = 35.2708\n",
    "# lon_buffer = 0.00200\n",
    "# lat_buffer = 0.00190\n",
    "\n",
    "lat = 30.2522\n",
    "lon = 30.5516\n",
    "buffer = 0.1\n",
    "\n",
    "x = (lon - buffer, lon + buffer)\n",
    "y =  (lat + buffer, lat - buffer)\n",
    "\n",
    "# Create a reusable query\n",
    "query = {\n",
    "    'x': x,\n",
    "    'y': y,\n",
    "    'time': ('2018-01', '2018-06'),\n",
    "    'resolution': (-20, 20),\n",
    "#     'dask_chunks':{'x':500, 'y':500,'time': -1}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_map(x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pixel quality parameters for USGS Collection 2\n",
      "Finding datasets\n",
      "    usgs_ls8c_level2_2\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 10 out of 11 time steps with at least 50.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 10 time steps\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (time: 10, x: 987, y: 1130)\n",
      "Coordinates:\n",
      "  * time         (time) datetime64[ns] 2018-01-12T08:30:07.070431 ... 2018-06-21T08:29:00.035786\n",
      "  * x            (x) float64 2.546e+05 2.546e+05 ... 2.742e+05 2.743e+05\n",
      "    spatial_ref  int32 0\n",
      "  * y            (y) float64 3.361e+06 3.361e+06 ... 3.338e+06 3.338e+06\n",
      "Data variables:\n",
      "    red          (time, y, x) float32 13686.0 16583.0 ... 19315.0 19315.0\n",
      "    nir          (time, y, x) float32 19431.0 20393.0 ... 21945.0 21945.0\n",
      "Attributes:\n",
      "    crs:           epsg:32636\n",
      "    grid_mapping:  spatial_ref\n"
     ]
    }
   ],
   "source": [
    "#find the most common UTM crs for the location\n",
    "output_crs = mostcommon_crs(dc=dc, product='usgs_ls8c_level2_2', query=query)\n",
    "\n",
    "# Load available data\n",
    "ds = load_ard(dc=dc, \n",
    "              products=['usgs_ls8c_level2_2'],\n",
    "              measurements=['red','nir'],\n",
    "              group_by='solar_day',\n",
    "              min_gooddata=0.5,\n",
    "              output_crs=output_crs, \n",
    "              **query)\n",
    "\n",
    "# Print output data\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate NDVI and DOY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rgb(ds, index=[0,2,4,6,8,10,12,14,16,18,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping bands ['red', 'nir']\n"
     ]
    }
   ],
   "source": [
    "# First we calculate NDVI on each image in the timeseries\n",
    "ndvi = calculate_indices(ds, index='NDVI', collection='c2', drop=True)\n",
    "ndvi = ndvi.NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi.mean(['x','y']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test each statistic\n",
    "\n",
    "After confirming each statistic is working, then adding the code to the `deafrica_phenology.py` script.\n",
    "\n",
    "Statistics to calculate:\n",
    "\n",
    "    SOS = DOY of start of season\n",
    "    POS = DOY of peak of season\n",
    "    EOS = DOY of end of season\n",
    "    vSOS = Value at start of season\n",
    "    vPOS = Value at peak of season\n",
    "    vEOS = Value at end of season\n",
    "    LOS = Length of season (DOY)\n",
    "    AOS = Amplitude of season (in value units)\n",
    "    IOS = Integral of season (SOS-EOS)\n",
    "    ROG = Rate of greening\n",
    "    ROS = Rate of senescence\n",
    "    SW = Skewness of growing season\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics that are working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi = ndvi.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolated dataset to 24 time-steps\n",
      "CPU times: user 1.25 s, sys: 497 ms, total: 1.75 s\n",
      "Wall time: 1.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pheno = xr_phenology(ndvi, \n",
    "                     stats=['SOS', 'POS','EOS','Trough','vSOS','vPOS',\n",
    "                            'vEOS', 'LOS', 'AOS','ROG','ROS'],\n",
    "                     interpolate_na=False,\n",
    "                     interpolate=True,\n",
    "                     method_sos='first',\n",
    "                     method_eos='last',\n",
    "                     interp_method = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pheno.vEOS.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pheno.vSOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    " This works...but only for 1D arrays. Could be good if used after zonal-stats are calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import xarray as xr\n",
    "# import pandas as pd\n",
    "# from scipy.integrate import trapz\n",
    "# from scipy.stats import skew\n",
    "\n",
    "# def _getPhenologyMetrics(da, doy):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Obtain land surfurface phenology metrics\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     - da:  xr.Datarray\n",
    "#     - doy: xt.DataArray\n",
    "#         Dayofyer values for each time step in the 'time'\n",
    "#         dim on 'da'. e.g doy=da.time.dt.dayofyear\n",
    "#     Outputs\n",
    "#     -------\n",
    "#         SOS = DOY of start of season\n",
    "#         POS = DOY of peak of season\n",
    "#         EOS = DOY of end of season\n",
    "#         vSOS = Value at start of season\n",
    "#         vPOS = Value at peak of season\n",
    "#         vEOS = Value at end of season\n",
    "#         LOS = Length of season (DOY)\n",
    "#         AOS = Amplitude of season (in value units)\n",
    "#         IOS = Integral of season (SOS-EOS)\n",
    "#         ROG = Rate of greening\n",
    "#         ROS = Rate of senescence\n",
    "#         SW = Skewness of growing season\n",
    "#     \"\"\"\n",
    "#     stats=[]\n",
    "    \n",
    "#     # basic variables\n",
    "#     vpos = np.nanmax(da)\n",
    "#     ipos = np.where(da == vpos)[0]\n",
    "#     print(ipos)\n",
    "#     pos = doy[ipos]\n",
    "#     trough = np.nanmin(da)\n",
    "#     ampl = vpos - trough\n",
    "\n",
    "#     # get position of seasonal peak and trough\n",
    "#     ipos = np.where(da == vpos)\n",
    "\n",
    "#     # scale annual time series to 0-1\n",
    "#     ratio = (da - trough) / ampl\n",
    "\n",
    "#     # separate greening from senesence values\n",
    "#     dev = np.gradient(ratio)  # first derivative\n",
    "#     greenup = np.zeros([ratio.shape[0]],  dtype=bool)\n",
    "#     greenup[dev > 0] = True\n",
    "\n",
    "#     # estimate SOS and EOS as median of the seasons\n",
    "#     i = np.nanmedian(doy[:ipos[0][0]][greenup[:ipos[0][0]]])\n",
    "#     ii = np.nanmedian(doy[ipos[0][0]:][~greenup[ipos[0][0]:]])\n",
    "#     sos = doy[(np.abs(doy - i)).argmin()]\n",
    "#     eos = doy[(np.abs(doy - ii)).argmin()]\n",
    "#     isos = np.where(doy == int(sos))[0]\n",
    "#     ieos = np.where(doy == eos)[0]\n",
    "#     if sos is None:\n",
    "#         isos = 0\n",
    "#         sos = doy[isos]\n",
    "#     if eos is None:\n",
    "#         ieos = len(doy) - 1\n",
    "#         eos = doy[ieos]\n",
    "\n",
    "#     # los: length of season\n",
    "#     los = eos - sos\n",
    "#     if los < 0:\n",
    "#         los[los < 0] = len(da) + \\\n",
    "#             (eos[los < 0] - sos[los < 0])\n",
    "\n",
    "#     # doy of growing season\n",
    "#     green = doy[(doy > sos) & (doy < eos)]\n",
    "#     _id = []\n",
    "#     for i in range(len(green)):\n",
    "#         _id.append((doy == green[i]).nonzero()[0])\n",
    "\n",
    "#     # index of growing season\n",
    "#     _id = np.array([item for sublist in _id for item in sublist])\n",
    "#     # get intergral of green season\n",
    "#     ios = trapz(da[_id], doy[_id])\n",
    "\n",
    "#     # rate of greening [slope SOS-POS]\n",
    "#     rog = (vpos - da[isos]) / (pos - sos)\n",
    "#     rog = rog[0]\n",
    "\n",
    "#     # rate of senescence [slope POS-EOS]\n",
    "#     ros = (da[ieos] - vpos) / (eos - pos)\n",
    "#     ros= ros[0]\n",
    "\n",
    "#     # skewness of growing season\n",
    "#     sw = skew(da[_id])\n",
    "\n",
    "#     #values at start of season\n",
    "#     vsos = da[isos][0]\n",
    "\n",
    "#     #values at end of season\n",
    "#     veos = da[ieos][0]\n",
    "    \n",
    "#     print(sos,pos[0],eos, vsos, vpos, veos, los, ampl, ios, rog, ros, sw)\n",
    "\n",
    "#     #return metrics\n",
    "\n",
    "# #create fake data\n",
    "# ndvi = np.array([0,0.0,0.2, 0.5, 0.9, 0.9, 0.9, 0.8, 0.75, 0.1, 0.0, 0.0])\n",
    "# test_da = xr.DataArray(ndvi,\n",
    "#              coords=[pd.date_range(\"01/01/2018\", periods=12, freq=pd.DateOffset(months=1),)],dims=\"time\")\n",
    "\n",
    "# doy=test_da.time.dt.dayofyear\n",
    "\n",
    "# xr.apply_ufunc(\n",
    "#         _getPhenologyMetrics,\n",
    "#         test_da,\n",
    "#         input_core_dims=[[\"time\"]],\n",
    "#         kwargs={'doy': doy.values},\n",
    "#         dask='allowed')\n",
    "\n",
    "# ax = plt.subplot(1, 1, 1)\n",
    "# ax.plot(doy, ndvi)\n",
    "# ax.plot(60,0.2, \"or\")\n",
    "# ax.plot(244,0.75, \"or\")\n",
    "# ax.plot(121, 0.9, \"or\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "ufunc for applying polynomial fits.  Works okay but is very slow. Better off using the `.resample().interpolate` xarray methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def poly_fit(time, data, degree):\n",
    "    \n",
    "#     pfit = np.polyfit(time, data, degree) \n",
    "    \n",
    "#     return np.transpose(np.polyval(pfit,time))\n",
    "\n",
    "# def poly_fit_smooth(time, data, degree, n_pts):\n",
    "#         \"\"\"\n",
    "#         \"\"\"\n",
    "    \n",
    "#         time_smooth_inds = np.linspace(0, len(time), n_pts)\n",
    "#         time_smooth = np.interp(time_smooth_inds, np.arange(len(time)), time)\n",
    "\n",
    "#         data_smooth = np.array([np.array([coef * (x_val ** current_degree) for\n",
    "#                                 coef, current_degree in zip(np.polyfit(time, data, degree),\n",
    "#                                 range(degree, -1, -1))]).sum() for x_val in time_smooth])\n",
    "\n",
    "#         return data_smooth\n",
    "\n",
    "# def xr_polyfit(doy,\n",
    "#                da,\n",
    "#                degree,\n",
    "#                interp_multiplier=1):    \n",
    "    \n",
    "#     # Fit polynomial curve to observed data points\n",
    "#     if interp_multiplier==1:\n",
    "#         print('Fitting polynomial curve to existing observations')\n",
    "#         pfit = xr.apply_ufunc(\n",
    "#             poly_fit,\n",
    "#             doy,\n",
    "#             da, \n",
    "#             kwargs={'degree':degree},\n",
    "#             input_core_dims=[[\"time\"], [\"time\"]], \n",
    "#             output_core_dims=[['time']],\n",
    "#             vectorize=True,  \n",
    "#             dask=\"parallelized\",\n",
    "#             output_dtypes=[da.dtype],\n",
    "#         )\n",
    "    \n",
    "#     if interp_multiplier > 1:\n",
    "#         print(\"Fitting polynomial curve to \"+str(len(doy)*interp_multiplier)+\n",
    "#                                                       \" interpolated points\")\n",
    "#         pfit = xr.apply_ufunc(\n",
    "#             poly_fit_smooth,  # The function\n",
    "#             doy,# time\n",
    "#             da,#.chunk({'time': -1}), #the data\n",
    "#             kwargs={'degree':degree, 'n_pts':len(doy)*interp_multiplier},\n",
    "#             input_core_dims=[[\"time\"], [\"time\"]], \n",
    "#             output_core_dims=[['new_time']], \n",
    "#             output_sizes = ({'new_time':len(doy)*interp_multiplier}),\n",
    "#             exclude_dims=set((\"time\",)),\n",
    "#             vectorize=True, \n",
    "#             dask=\"parallelized\",\n",
    "#             output_dtypes=[da.dtype],\n",
    "#         ).rename({'new_time':'time'})\n",
    "    \n",
    "#         # Map 'dayofyear' onto interpolated time dim\n",
    "#         time_smooth_inds = np.linspace(0, len(doy), len(doy)*interp_multiplier)\n",
    "#         new_datetimes = np.interp(time_smooth_inds, np.arange(len(doy)), doy)\n",
    "#         pfit = pfit.assign_coords({'time':new_datetimes})\n",
    "    \n",
    "#     return pfit\n",
    "\n",
    "# # da=xr_polyfit(dayofyear=dayofyear, \n",
    "# #               da=da,\n",
    "# #               degree=degree,\n",
    "# #               interp_multiplier=interp_multiplier)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
