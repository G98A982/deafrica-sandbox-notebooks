{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction <img align=\"right\" src=\"../Supplementary_data/DE_Africa_Logo_Stacked_RGB_small.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "from odc.algo import xr_geomedian\n",
    "import xarray as xr\n",
    "import subprocess as sp\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "\n",
    "import sys\n",
    "sys.path.append('../Scripts')\n",
    "from deafrica_datahandling import load_ard\n",
    "from deafrica_classificationtools import predict_xr\n",
    "from deafrica_dask import create_local_dask_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a dask cluster\n",
    "This will help keep our memory use down and conduct the analysis in parallel. If you'd like to view the dask dashboard, click on the hyperlink that prints below the cell. You can use the dashboard to monitor the progress of calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis parameters\n",
    "\n",
    "* `ncpus`: Set this value to > 1 to parallize the collection of training data. eg. npus=8. \n",
    "* `model`: Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically detect number of cpus, adjust to [-3:] if working on deafault Sandbox\n",
    "ncpus= int(float(sp.getoutput('env | grep CPU')[-4:]))\n",
    "\n",
    "model_path = 'results/ml_model.joblib'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract feature layers from datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_ard(dc=dc, \n",
    "              products=['s2_l2a'],\n",
    "              dask_chunks={'x':2000, 'y':2000},\n",
    "              dtype='native',\n",
    "              **query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_epochs_MADS(ds):\n",
    "    dc = datacube.Datacube(app='training')\n",
    "    \n",
    "    epoch1_gm = geomedian = int_geomedian(ds)\n",
    "    epoch1_gm = calculate_indices(epoch1_gm,\n",
    "                             index=['NDVI', 'LAI'],\n",
    "                             drop=False,\n",
    "                             collection='s2')\n",
    "    \n",
    "    stats = TernaryMAD(num_threads=1)\n",
    "    epoch1_mad = stats.compute(data=ds)\n",
    "    epoch1_mad.coords['x'] = ds.x\n",
    "    epoch1_mad.coords['y'] = ds.y\n",
    "    \n",
    "    q = {\n",
    "    'geopolygon':ds.geobox.extent,\n",
    "    'time': ('2019-07', '2019-12'),\n",
    "    'measurements': ['blue','green','red','nir','swir_1','swir_2'],\n",
    "    'resolution': (-20, 20),\n",
    "    'group_by' :'solar_day',\n",
    "    'output_crs':'epsg:6933'}\n",
    "    \n",
    "\n",
    "    print('epoch 2')    \n",
    "    ds2 = load_ard(dc=dc,products=['s2_l2a'],**q)    \n",
    "    epoch2_gm = GeoMedian().compute(ds2)\n",
    "    epoch2_gm = calculate_indices(epoch2_gm,\n",
    "                             index=['NDVI', 'LAI'],\n",
    "                             drop=False,\n",
    "                             collection='s2')\n",
    "    \n",
    "    epoch2_gm = epoch2_gm.rename({\n",
    "                     'blue':'blue_2',\n",
    "                     'green':'green_2',\n",
    "                     'red':'red_2',\n",
    "                     'nir':'nir_2',\n",
    "                     'swir_1':'swir_1_2',\n",
    "                     'swir_2':'swir_2_2',\n",
    "                     'NDVI':'NDVI_2',\n",
    "                     'LAI':'LAI_2'\n",
    "                      })\n",
    "    \n",
    "    stats = TernaryMAD(num_threads=1)\n",
    "    epoch2_mad = stats.compute(data=ds2)\n",
    "    epoch2_mad.coords['x'] = ds2.x\n",
    "    epoch2_mad.coords['y'] = ds2.y\n",
    "    epoch2_mad = epoch2_mad.rename({\n",
    "        'sdev':'sdev_2',\n",
    "        'edev':'edev_2',\n",
    "        'bcdev':'bcdev_2'\n",
    "    })\n",
    "\n",
    "    print('slope...')\n",
    "    slope = dc.load(product='srtm', like=ds.geobox).squeeze()\n",
    "    slope = slope.elevation\n",
    "    slope = xr_terrain(slope, 'slope_riserun')\n",
    "    slope = slope.to_dataset(name='slope')\n",
    "    \n",
    "    print('Merging...')\n",
    "    result = xr.merge([epoch1_gm,\n",
    "                       epoch1_mad,\n",
    "                       epoch2_gm,\n",
    "                       epoch2_mad,\n",
    "                       slope], compat='override')\n",
    "\n",
    "    return result.squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predict_xr(model, data, progress=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
