{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction <img align=\"right\" src=\"../Supplementary_data/DE_Africa_Logo_Stacked_RGB_small.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "from odc.algo import xr_geomedian\n",
    "import xarray as xr\n",
    "import subprocess as sp\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "import geopandas as gpd\n",
    "from datacube.utils import geometry\n",
    "from datacube.utils.cog import write_cog\n",
    "from datacube.utils.geometry import assign_crs\n",
    "\n",
    "import sys\n",
    "sys.path.append('../Scripts')\n",
    "from deafrica_datahandling import load_ard\n",
    "from deafrica_classificationtools import predict_xr#,predict_proba_xr\n",
    "from deafrica_dask import create_local_dask_cluster\n",
    "from deafrica_plotting import map_shapefile\n",
    "from deafrica_bandindices import calculate_indices\n",
    "from deafrica_temporal_statistics import temporal_statistics\n",
    "\n",
    "sys.path.append('../datacube-2nd-order-stats')\n",
    "from model import TernaryMAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a dask cluster\n",
    "This will help keep our memory use down and conduct the analysis in parallel. If you'd like to view the dask dashboard, click on the hyperlink that prints below the cell. You can use the dashboard to monitor the progress of calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:33157</li>\n",
       "  <li><b>Dashboard: </b><a href='/user/chad/proxy/8787/status' target='_blank'>/user/chad/proxy/8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>15</li>\n",
       "  <li><b>Memory: </b>104.37 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:33157' processes=1 threads=15, memory=104.37 GB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis parameters\n",
    "\n",
    "* `ncpus`: Set this value to > 1 to parallize the collection of training data. eg. npus=8. \n",
    "* `model`: Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncpus = 15\n"
     ]
    }
   ],
   "source": [
    "# automatically detect number of cpus, adjust to [-3:] if working on deafault Sandbox\n",
    "ncpus= int(float(sp.getoutput('env | grep CPU')[-4:]))\n",
    "\n",
    "model_path = 'results/ml_model.joblib'\n",
    "\n",
    "print('ncpus = '+str(ncpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open 'tiles' shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read shapefile\n",
    "gdf = gpd.read_file('../crop_mask/data/tiles.shp')\n",
    "\n",
    "#open shapefile\n",
    "aez=gpd.read_file('../crop_mask/data/AEZs/Southern.shp')\n",
    "\n",
    "# clip points to region\n",
    "gdf = gpd.overlay(gdf, aez, how='intersection')\n",
    "\n",
    "# add an ID column\n",
    "gdf['id']=range(0, len(gdf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ead2e2b77b943dbb31ffd7498779059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b437ea01004c868b543a6ce570ddcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-33.51664688303821, 20.582205531194205], controls=(ZoomControl(options=['position', 'zoom_in_text'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print gdf\n",
    "list_of_tiles = [3,6,9,11,17,26]\n",
    "\n",
    "map_shapefile(gdf.iloc[list_of_tiles], 'id', hover_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction\n",
    "\n",
    "Extract data from the datacube exactly matching the feature layers we created during the extraction of training data in script `1_Extract_training_data.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xr_terrain(da, attribute=None):\n",
    "    \"\"\"\n",
    "    Using the richdem package, calculates terrain attributes\n",
    "    on a DEM stored in memory as an xarray.DataArray \n",
    "    \n",
    "    Params\n",
    "    -------\n",
    "    da : xr.DataArray\n",
    "    attribute : str\n",
    "        One of the terrain attributes that richdem.TerrainAttribute()\n",
    "        has implemented. e.g. 'slope_riserun', 'slope_percentage', 'aspect'.\n",
    "        See all option here:  \n",
    "        https://richdem.readthedocs.io/en/latest/python_api.html#richdem.TerrainAttribute\n",
    "        \n",
    "    \"\"\"\n",
    "    #remove time if its there\n",
    "    da = da.squeeze()\n",
    "    #convert to richdem array\n",
    "    rda = rd.rdarray(da.data, no_data=da.attrs['nodata'])\n",
    "    #add projection and geotransform\n",
    "    rda.projection=pyproj.crs.CRS(da.attrs['crs']).to_wkt()\n",
    "    rda.geotransform = da.geobox.affine.to_gdal()\n",
    "    #calulate attribute\n",
    "    attrs = rd.TerrainAttribute(rda, attrib=attribute)\n",
    "\n",
    "    #return as xarray DataArray\n",
    "    return xr.DataArray(attrs,\n",
    "                        attrs=da.attrs,\n",
    "                        coords={'x':da.x, 'y':da.y},\n",
    "                        dims=['y', 'x'])\n",
    "\n",
    "def two_epochs_gm_mads(ds):\n",
    "    dc = datacube.Datacube(app='training')\n",
    "    \n",
    "    ds1 = ds.sel(time=slice('2019-01', '2019-06'))\n",
    "    ds2 = ds.sel(time=slice('2019-07', '2019-12')) \n",
    "    \n",
    "    def fun(ds, era):\n",
    "        print('  geomedian')\n",
    "        gm = xr_geomedian(ds).compute()\n",
    "        gm = calculate_indices(gm,\n",
    "                               index=['NDVI', 'LAI'],\n",
    "                               drop=False,\n",
    "                               collection='s2')\n",
    "        gm = gm.rename({\n",
    "                 'blue':'blue_'+era,\n",
    "                 'green':'green_'+era,\n",
    "                 'red':'red_'+era,\n",
    "                 'nir':'nir_'+era,\n",
    "                 'swir_1':'swir_1_'+era,\n",
    "                 'swir_2':'swir_2_'+era,\n",
    "                 'NDVI':'NDVI_'+era,\n",
    "                 'LAI':'LAI_'+era\n",
    "                  })\n",
    "        \n",
    "        print('  TMADs')\n",
    "        stats = TernaryMAD(num_threads=ncpus)\n",
    "        mad = stats.compute(data=ds)\n",
    "        mad.coords['x'] = ds.x\n",
    "        mad.coords['y'] = ds.y\n",
    "        mad = mad.rename({\n",
    "            'sdev':'sdev_'+era,\n",
    "            'edev':'edev_'+era,\n",
    "            'bcdev':'bcdev_'+era\n",
    "        })\n",
    "        \n",
    "        return gm,mad\n",
    "    \n",
    "    epoch1_gm, epoch1_mad = fun(ds1, era='S1')\n",
    "    epoch2_gm, epoch2_mad = fun(ds2, era='S2')\n",
    "    \n",
    "    print('   Slope')\n",
    "    slope = dc.load(product='srtm', like=ds.geobox).squeeze()\n",
    "    slope = slope.elevation\n",
    "    slope = xr_terrain(slope, 'slope_riserun')\n",
    "    slope = slope.to_dataset(name='slope')\n",
    "    print('   merge')\n",
    "    result = xr.merge([epoch1_gm,\n",
    "                       epoch1_mad,\n",
    "                       epoch2_gm,\n",
    "                       epoch2_mad,\n",
    "                       slope], compat='override')\n",
    "\n",
    "    return result.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up our inputs to collect_training_data\n",
    "products =  ['s2_l2a']\n",
    "time = ('2019-01','2019-12')\n",
    "\n",
    "# Set up the inputs for the ODC query\n",
    "measurements =  ['red', 'green', 'nir', 'blue', 'swir_1', 'swir_2']\n",
    "resolution = (-20,20)\n",
    "output_crs='epsg:6933'\n",
    "dask_chunks={'x':1000,'y':1000,'time':-1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on tile: 3\n",
      "Using pixel quality parameters for Sentinel 2\n",
      "Finding datasets\n",
      "    s2_l2a\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 145 time steps as a dask array\n",
      "  geomedian\n",
      "  TMADs\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The da.median function only works along an axis.  The full algorithm is difficult to do in parallel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-942a9b036fa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m                   **query)\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwo_epochs_gm_mads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#predict using the imported model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2786a5d60396>\u001b[0m in \u001b[0;36mtwo_epochs_gm_mads\u001b[0;34m(ds)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mepoch1_gm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch1_mad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mera\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'S1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mepoch2_gm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch2_mad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mera\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'S2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'   Slope'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2786a5d60396>\u001b[0m in \u001b[0;36mfun\u001b[0;34m(ds, era)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  TMADs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTernaryMAD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mncpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mmad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mmad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mmad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/deafrica-sandbox-notebooks/datacube-2nd-order-stats/model/__init__.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mfdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msquashed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_on_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sdev\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/deafrica-sandbox-notebooks/datacube-2nd-order-stats/model/__init__.py\u001b[0m in \u001b[0;36mcompute_on_array\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mndepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mmindepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmediandepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0mLOG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data mindepth: %s maxdepth: %s mediandepth: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmindepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmediandepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/dask/array/core.py\u001b[0m in \u001b[0;36m__array_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mda_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_nonmatching_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1385\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mda_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/dask/array/reductions.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, keepdims, out)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m         raise NotImplementedError(\n\u001b[0;32m-> 1290\u001b[0;31m             \u001b[0;34m\"The da.median function only works along an axis.  \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1291\u001b[0m             \u001b[0;34m\"The full algorithm is difficult to do in parallel\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m         )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The da.median function only works along an axis.  The full algorithm is difficult to do in parallel"
     ]
    }
   ],
   "source": [
    "tiles_classified = []\n",
    "\n",
    "for index, row in gdf.iloc[list_of_tiles].iterrows():\n",
    "\n",
    "    print(\"Working on tile: \"+str(gdf['id'][index]))\n",
    "    \n",
    "    # generate a datacube query object\n",
    "    query = {\n",
    "        'time': time,\n",
    "        'measurements': measurements,\n",
    "        'resolution': resolution,\n",
    "        'output_crs': output_crs,\n",
    "        'group_by' : 'solar_day',\n",
    "    }\n",
    "    \n",
    "    # Get the geometry\n",
    "    geom = geometry.Geometry(row.geometry.__geo_interface__,\n",
    "                             geometry.CRS(f'EPSG:{gdf.crs.to_epsg()}'))\n",
    "    \n",
    "    # Update dc query with geometry      \n",
    "    query.update({'geopolygon': geom})\n",
    "\n",
    "    ds = load_ard(dc=dc,\n",
    "                  products=products,\n",
    "                  dask_chunks=dask_chunks,\n",
    "                  **query)\n",
    "\n",
    "    data = two_epochs_gm_mads(ds)\n",
    "    \n",
    "    #predict using the imported model\n",
    "    print('predicting...')\n",
    "    predicted = predict_xr(model, data.squeeze(), progress=True)\n",
    "    tiles_classified.append(predicted)    \n",
    "    write_cog(predicted, 'results/classifications/Southern_'+ str(row['id'])+'_prediction.tif')\n",
    "    \n",
    "#     predicted_proba = predict_proba_xr(model, data.squeeze(), progress=True)\n",
    "#     write_cog(predicted_proba, 'results/classifications/Southern_'+ row['id']+'_prediction_proba.tif')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
