{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction <img align=\"right\" src=\"../Supplementary_data/DE_Africa_Logo_Stacked_RGB_small.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install richdem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.6/site-packages/datacube/storage/masking.py:4: DeprecationWarning: datacube.storage.masking has moved to datacube.utils.masking\n",
      "  category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import datacube\n",
    "from odc.algo import xr_geomedian, int_geomedian\n",
    "import xarray as xr\n",
    "import subprocess as sp\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "import geopandas as gpd\n",
    "from datacube.utils import geometry\n",
    "from datacube.utils.cog import write_cog\n",
    "from datacube.utils.geometry import assign_crs\n",
    "import richdem as rd\n",
    "\n",
    "import sys\n",
    "sys.path.append('../Scripts')\n",
    "from deafrica_datahandling import load_ard\n",
    "from deafrica_classificationtools import predict_xr#,predict_proba_xr\n",
    "from deafrica_dask import create_local_dask_cluster\n",
    "from deafrica_plotting import map_shapefile\n",
    "from deafrica_bandindices import calculate_indices\n",
    "from deafrica_temporal_statistics import temporal_statistics\n",
    "\n",
    "sys.path.append('../datacube-2nd-order-stats')\n",
    "from model import TernaryMAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a dask cluster\n",
    "This will help keep our memory use down and conduct the analysis in parallel. If you'd like to view the dask dashboard, click on the hyperlink that prints below the cell. You can use the dashboard to monitor the progress of calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:46365</li>\n",
       "  <li><b>Dashboard: </b><a href='/user/chad/proxy/8787/status' target='_blank'>/user/chad/proxy/8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>15</li>\n",
       "  <li><b>Memory: </b>104.37 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:46365' processes=1 threads=15, memory=104.37 GB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis parameters\n",
    "\n",
    "* `ncpus`: Set this value to > 1 to parallelize the collection of training data. eg. npus=8. \n",
    "* `model`: Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncpus = 15\n"
     ]
    }
   ],
   "source": [
    "# automatically detect number of cpus, adjust to [-3:] if working on deafault Sandbox\n",
    "ncpus= int(float(sp.getoutput('env | grep CPU')[-4:]))\n",
    "\n",
    "model_path = 'results/ml_model.joblib'\n",
    "\n",
    "print('ncpus = '+str(ncpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open 'tiles' shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read shapefile\n",
    "gdf = gpd.read_file('../crop_mask/data/tiles.shp')\n",
    "\n",
    "#open shapefile\n",
    "aez=gpd.read_file('../crop_mask/data/AEZs/Southern.shp')\n",
    "\n",
    "# clip points to region\n",
    "gdf = gpd.overlay(gdf, aez, how='intersection')\n",
    "\n",
    "# add an ID column\n",
    "gdf['id']=range(0, len(gdf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cbb6bf96cd04afe92c98a76896be686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6500e50887459a99bc374c93c97a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-33.51664688303821, 20.582205531194205], controls=(ZoomControl(options=['position', 'zoom_in_text'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print gdf\n",
    "list_of_tiles = [3,6,9,11,17,26]\n",
    "\n",
    "map_shapefile(gdf.iloc[list_of_tiles], 'id', hover_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction\n",
    "\n",
    "Extract data from the datacube exactly matching the feature layers we created during the extraction of training data in script `1_Extract_training_data.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xr_terrain(da, attribute=None):\n",
    "    \"\"\"\n",
    "    Using the richdem package, calculates terrain attributes\n",
    "    on a DEM stored in memory as an xarray.DataArray \n",
    "    \n",
    "    Params\n",
    "    -------\n",
    "    da : xr.DataArray\n",
    "    attribute : str\n",
    "        One of the terrain attributes that richdem.TerrainAttribute()\n",
    "        has implemented. e.g. 'slope_riserun', 'slope_percentage', 'aspect'.\n",
    "        See all option here:  \n",
    "        https://richdem.readthedocs.io/en/latest/python_api.html#richdem.TerrainAttribute\n",
    "        \n",
    "    \"\"\"\n",
    "    #remove time if its there\n",
    "    da = da.squeeze()\n",
    "    #convert to richdem array\n",
    "    rda = rd.rdarray(da.data, no_data=da.attrs['nodata'])\n",
    "    #add projection and geotransform\n",
    "    rda.projection=pyproj.crs.CRS(da.attrs['crs']).to_wkt()\n",
    "    rda.geotransform = da.geobox.affine.to_gdal()\n",
    "    #calulate attribute\n",
    "    attrs = rd.TerrainAttribute(rda, attrib=attribute)\n",
    "\n",
    "    #return as xarray DataArray\n",
    "    return xr.DataArray(attrs,\n",
    "                        attrs=da.attrs,\n",
    "                        coords={'x':da.x, 'y':da.y},\n",
    "                        dims=['y', 'x'])\n",
    "\n",
    "def two_epochs_gm_mads(ds):\n",
    "    dc = datacube.Datacube(app='training')\n",
    "    \n",
    "    \n",
    "    ds1 = ds.sel(time=slice('2019-01', '2019-06'))\n",
    "    ds2 = ds.sel(time=slice('2019-07', '2019-12'))\n",
    "    \n",
    "    def fun(ds, era):\n",
    "        ds = ds.compute()\n",
    "        print(ds)\n",
    "        print('  geomedian')\n",
    "        gm = int_geomedian(ds.chunk({'x':2000,'y':2000,'time':1})).compute()\n",
    "        gm = calculate_indices(gm,\n",
    "                               index=['NDVI', 'LAI'],\n",
    "                               drop=False,\n",
    "                               collection='s2')\n",
    "        gm = gm.rename({\n",
    "                 'blue':'blue_'+era,\n",
    "                 'green':'green_'+era,\n",
    "                 'red':'red_'+era,\n",
    "                 'nir':'nir_'+era,\n",
    "                 'swir_1':'swir_1_'+era,\n",
    "                 'swir_2':'swir_2_'+era,\n",
    "                 'NDVI':'NDVI_'+era,\n",
    "                 'LAI':'LAI_'+era\n",
    "                  })\n",
    "        \n",
    "        \n",
    "        print('  TMADs')\n",
    "        stats = TernaryMAD(num_threads=ncpus)\n",
    "        mad = stats.compute(data=ds)\n",
    "        mad.coords['x'] = ds.x\n",
    "        mad.coords['y'] = ds.y\n",
    "        mad = mad.rename({\n",
    "            'sdev':'sdev_'+era,\n",
    "            'edev':'edev_'+era,\n",
    "            'bcdev':'bcdev_'+era\n",
    "        })\n",
    "        \n",
    "        return gm,mad\n",
    "    \n",
    "    epoch1_gm, epoch1_mad = fun(ds1, era='S1')\n",
    "    epoch2_gm, epoch2_mad = fun(ds2, era='S2')\n",
    "    \n",
    "    print('   Slope')\n",
    "    slope = dc.load(product='srtm', like=ds.geobox).squeeze()\n",
    "    slope = slope.elevation\n",
    "    slope = xr_terrain(slope, 'slope_riserun')\n",
    "    slope = slope.to_dataset(name='slope')\n",
    "    print('   merge')\n",
    "    result = xr.merge([epoch1_gm,\n",
    "                       epoch1_mad,\n",
    "                       epoch2_gm,\n",
    "                       epoch2_mad,\n",
    "                       slope], compat='override')\n",
    "\n",
    "    return result.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up our inputs to collect_training_data\n",
    "products =  ['s2_l2a']\n",
    "time = ('2019-01','2019-12')\n",
    "\n",
    "# Set up the inputs for the ODC query\n",
    "measurements =  ['red', 'green', 'nir', 'blue', 'swir_1', 'swir_2']\n",
    "resolution = (-20,20)\n",
    "output_crs='epsg:6933'\n",
    "dask_chunks={'x':2000,'y':2000,'time':-1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on tile: 3\n",
      "Using pixel quality parameters for Sentinel 2\n",
      "Finding datasets\n",
      "    s2_l2a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/deafrica_datahandling.py:240: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting good quality pixels for each time step\n",
      "Filtering to 120 out of 145 time steps with at least 25.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 120 time steps as a dask array\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (time: 120, x: 3910, y: 7501)\n",
      "Coordinates:\n",
      "  * time         (time) datetime64[ns] 2019-01-01T08:49:18 ... 2019-12-30T08:...\n",
      "  * y            (y) float64 -3.9e+06 -3.9e+06 -3.9e+06 ... -4.05e+06 -4.05e+06\n",
      "    spatial_ref  int32 6933\n",
      "  * x            (x) float64 1.722e+06 1.722e+06 1.722e+06 ... 1.8e+06 1.8e+06\n",
      "Data variables:\n",
      "    red          (time, y, x) uint16 dask.array<chunksize=(120, 2000, 2000), meta=np.ndarray>\n",
      "    green        (time, y, x) uint16 dask.array<chunksize=(120, 2000, 2000), meta=np.ndarray>\n",
      "    nir          (time, y, x) uint16 dask.array<chunksize=(120, 2000, 2000), meta=np.ndarray>\n",
      "    blue         (time, y, x) uint16 dask.array<chunksize=(120, 2000, 2000), meta=np.ndarray>\n",
      "    swir_1       (time, y, x) uint16 dask.array<chunksize=(120, 2000, 2000), meta=np.ndarray>\n",
      "    swir_2       (time, y, x) uint16 dask.array<chunksize=(120, 2000, 2000), meta=np.ndarray>\n",
      "Attributes:\n",
      "    crs:           epsg:6933\n",
      "    grid_mapping:  spatial_ref\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (time: 60, x: 3910, y: 7501)\n",
      "Coordinates:\n",
      "  * time         (time) datetime64[ns] 2019-01-01T08:49:18 ... 2019-06-28T08:...\n",
      "  * y            (y) float64 -3.9e+06 -3.9e+06 -3.9e+06 ... -4.05e+06 -4.05e+06\n",
      "    spatial_ref  int32 6933\n",
      "  * x            (x) float64 1.722e+06 1.722e+06 1.722e+06 ... 1.8e+06 1.8e+06\n",
      "Data variables:\n",
      "    red          (time, y, x) uint16 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0\n",
      "    green        (time, y, x) uint16 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0\n",
      "    nir          (time, y, x) uint16 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0\n",
      "    blue         (time, y, x) uint16 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0\n",
      "    swir_1       (time, y, x) uint16 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0\n",
      "    swir_2       (time, y, x) uint16 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0\n",
      "Attributes:\n",
      "    crs:           epsg:6933\n",
      "    grid_mapping:  spatial_ref\n",
      "  geomedian\n"
     ]
    }
   ],
   "source": [
    "tiles_classified = []\n",
    "\n",
    "for index, row in gdf.iloc[list_of_tiles].iterrows():\n",
    "\n",
    "    print(\"Working on tile: \"+str(gdf['id'][index]))\n",
    "    \n",
    "    # generate a datacube query object\n",
    "    query = {\n",
    "        'time': time,\n",
    "        'measurements': measurements,\n",
    "        'resolution': resolution,\n",
    "        'output_crs': output_crs,\n",
    "        'group_by' : 'solar_day',\n",
    "    }\n",
    "    \n",
    "    # Get the geometry\n",
    "    geom = geometry.Geometry(row.geometry.__geo_interface__,\n",
    "                             geometry.CRS(f'EPSG:{gdf.crs.to_epsg()}'))\n",
    "    \n",
    "    # Update dc query with geometry      \n",
    "    query.update({'geopolygon': geom})\n",
    "\n",
    "    ds = load_ard(dc=dc,\n",
    "                  products=products,\n",
    "                  dask_chunks=dask_chunks,\n",
    "                  min_gooddata=0.25,\n",
    "                  dtype='native',\n",
    "                  **query)\n",
    "    print(ds)\n",
    "    data = two_epochs_gm_mads(ds)\n",
    "    \n",
    "    #predict using the imported model\n",
    "    print('predicting...')\n",
    "    predicted = predict_xr(model, data.squeeze(), progress=True)\n",
    "    tiles_classified.append(predicted)    \n",
    "    write_cog(predicted, 'results/classifications/Southern_'+ str(row['id'])+'_prediction.tif')\n",
    "    \n",
    "#     predicted_proba = predict_proba_xr(model, data.squeeze(), progress=True)\n",
    "#     write_cog(predicted_proba, 'results/classifications/Southern_'+ row['id']+'_prediction_proba.tif')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr = ds.red.isel(time=0)\n",
    "# template = xr.zeros_like(arr).to_dataset(name='edev')\n",
    "# template['sdev'] = xr.zeros_like(arr)\n",
    "# template['bcdev'] = xr.zeros_like(arr)\n",
    "# template = template.drop(['spatial_ref', 'time'])\n",
    "# template\n",
    "\n",
    "# stats = TernaryMAD(num_threads=1)\n",
    "# mad = ds.chunk(d).map_blocks(\n",
    "#             stats.compute(data=ds), template=template\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
